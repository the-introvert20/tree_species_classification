# ğŸŒ³ Tree Species Classification & Intelligence Assistant



## ğŸ¯ Overview

The **Tree Species Classification & Intelligence Assistant** is a comprehensive machine learning solution that combines:
- **ğŸŒ Location Intelligence**: K-NN based tree species recommendations
- **ğŸ” Species Discovery**: Geographic distribution analysis
- **ğŸ“¸ Image Classification**: CNN-powered visual tree identification
- **ğŸ“Š Data Analytics**: Insights from 1.38M+ tree records

Built with modern ML frameworks and deployed as an interactive web application.

---


---
## ğŸš€ Quick Start

### Prerequisites
- Python 3.13+
- pip package manager
- 4GB+ RAM (for CNN model loading)

### Installation & Setup

```bash
# Clone the repository
git clone https://github.com/the-introvert20/tree_species_classification.git
cd TREE_SPECIES_CLASSIFICATION

# Install dependencies
pip install -r requirements.txt

# Download the CNN model (255MB)
# Note: The CNN model is not included in the repository due to size limitations
# You can train your own using the tree_CNN.ipynb notebook or contact the author

# Run the application
streamlit run streamlit_integrated.py
```

ğŸŒ **Access the app**: Open your browser and navigate to `http://localhost:8501`

---

## âœ¨ Features & Capabilities

### ğŸŒ² 1. Smart Location-Based Recommendations
- **Input**: GPS coordinates, tree diameter, native status, city/state
- **Output**: Top 5 most likely tree species for the location
- **Algorithm**: K-Nearest Neighbors with geospatial clustering
- **Use Case**: Urban planning, forestry management, biodiversity studies

### ğŸ“ 2. Species Distribution Mapping  
- **Input**: Select any tree species from dropdown
- **Output**: Geographic distribution and common locations
- **Features**: City-wise prevalence analysis
- **Use Case**: Conservation planning, habitat studies

### ğŸ“· 3. AI-Powered Image Classification
- **Input**: Upload tree images (leaves, bark, full tree)
- **Output**: Species prediction with confidence scores
- **Technology**: Custom CNN trained on 30+ species (255MB model)
- **Accuracy**: ~26% on validation set (challenging real-world dataset)
- **Note**: CNN model file not included in repo due to size - train using `tree_CNN.ipynb`

---

## ğŸ—„ï¸ Dataset & Data Sources

### ğŸ“Š Tree Metadata Repository
| **Attribute** | **Details** |
|---------------|-------------|
| **Source** | Municipal tree surveys from 50+ U.S. cities |
| **Total Records** | ~1.38 million georeferenced trees |
| **Coverage** | Louisville, Chicago, NYC, LA, and more |
| **Key Fields** | Species names, GPS coordinates, diameter, native status |
| **Time Period** | 2018-2022 survey data |

**Key Data Columns:**
- `common_name`: Tree species (e.g., Bur Oak)
- `scientific_name`: Botanical name (e.g., Quercus macrocarpa)  
- `latitude_coordinate`, `longitude_coordinate`: GPS location
- `city`, `state`, `address`: Geographic identifiers
- `native`: Whether the tree is native to the area
- `diameter_breast_height_CM`: Tree measurement standard

### ğŸ–¼ï¸ Image Classification Dataset
| **Attribute** | **Details** |
|---------------|-------------|
| **Species Count** | 30 common North American species |
| **Total Images** | 1,454 curated samples |
| **Resolution** | Standardized to 224Ã—224 pixels |
| **Augmentation** | Rotation, zoom, flip transformations |
| **Quality** | Real-world conditions (varying lighting, angles) |

**Dataset Structure:** Folder-based organization with each folder named after tree species for supervised learning.

---

## ğŸ§  Machine Learning Architecture

<div align="center">
<img src="docs/cnn_architecture.png" alt="CNN Architecture" width="800">
<p><em>Custom CNN Architecture for Tree Species Image Classification</em></p>
</div>

### ğŸ” Location-Based Recommender System
```
Input: [Latitude, Longitude, Diameter, Native_Status, City, State]
    â†“
Preprocessing: StandardScaler + LabelEncoder
    â†“
K-Nearest Neighbors (k=5)
    â†“
Output: Top 5 Recommended Species
```

**Technical Details:**
- **Algorithm**: scikit-learn `NearestNeighbors`
- **Distance Metric**: Euclidean distance in scaled feature space
- **Features**: Geographic + environmental + biological attributes
- **Performance**: Sub-second response time for 1.38M records

### ğŸ§  CNN Image Classifier
```
Input: 224Ã—224Ã—3 RGB Image
    â†“
Conv2D(32) â†’ MaxPool â†’ Conv2D(64) â†’ MaxPool
    â†“
Conv2D(128) â†’ MaxPool â†’ Dropout(0.25)
    â†“
Flatten â†’ Dense(512) â†’ Dropout(0.5) â†’ Dense(30)
    â†“
Output: Species Probability Distribution
```

**Model Specifications:**
- **Framework**: TensorFlow/Keras
- **Architecture**: Sequential CNN with dropout regularization
- **Loss Function**: Categorical Crossentropy
- **Optimizer**: Adam (learning_rate=0.001)
- **Training**: 50 epochs with validation monitoring
- **Model Size**: 255MB (`basic_cnn_tree_species.h5`)

### ğŸ“Š Data Pipeline & Preprocessing
- **Encoding**: LabelEncoder for categorical variables
- **Scaling**: StandardScaler for numerical features
- **Image Processing**: Normalization to [0,1] range
- **Data Augmentation**: ImageDataGenerator with geometric transforms
- **Train/Validation Split**: 80/20 stratified sampling

---

## ğŸ› ï¸ Technical Implementation

### ğŸ“ Project Structure
```
TREE_SPECIES_CLASSIFICATION/
â”œâ”€â”€ ğŸ“Š Data Processing
â”‚   â”œâ”€â”€ 5M_trees.ipynb          # Train recommender system
â”‚   â””â”€â”€ tree_CNN.ipynb          # Train CNN classifier
â”œâ”€â”€ ğŸš€ Production Application  
â”‚   â”œâ”€â”€ streamlit_integrated.py # Main web application
â”‚   â””â”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ ğŸ¤– Trained Models
â”‚   â”œâ”€â”€ tree_data.pkl          # Processed dataset (1.9MB)
â”‚   â”œâ”€â”€ scaler.joblib          # Feature scaler (<1MB)
â”‚   â”œâ”€â”€ nn_model.joblib        # KNN model (1MB)
â”‚   â””â”€â”€ basic_cnn_tree_species.h5  # CNN model (255MB)
â””â”€â”€ ğŸ“š Documentation
    â”œâ”€â”€ README.md              # This file
    â””â”€â”€ PRODUCTION_READY.md    # Deployment guide
```

### âš™ï¸ System Requirements
| **Component** | **Requirement** |
|---------------|-----------------|
| **Python** | 3.13+ (tf-nightly compatible) |
| **Memory** | 4GB+ RAM for model loading |
| **Storage** | 2GB+ for models and data |
| **GPU** | Optional (CPU inference supported) |

### ğŸ”§ Dependencies
```python
streamlit>=1.28.0      # Web application framework
tensorflow>=2.15.0     # Deep learning (use tf-nightly for Python 3.13)
scikit-learn>=1.3.0    # Machine learning algorithms
pandas>=2.0.0          # Data manipulation
numpy>=1.24.0          # Numerical computing
pillow>=9.5.0          # Image processing
joblib>=1.3.0          # Model serialization
```

---

## ğŸ“‹ Complete Setup & Usage Guide

### Step 1: Environment Setup
```bash
# Clone repository
git clone https://github.com/the-introvert20/tree_species_classification.git
cd TREE_SPECIES_CLASSIFICATION

# Create virtual environment (recommended)
python -m venv tree_env
tree_env\Scripts\activate  # Windows
# source tree_env/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### Step 2: Model Training (Optional - Models Included)
```bash
# Train recommender system (generates tree_data.pkl, scaler.joblib, nn_model.joblib)
jupyter notebook 5M_trees.ipynb

# Train CNN classifier (generates basic_cnn_tree_species.h5)
jupyter notebook tree_CNN.ipynb
```

### Step 3: Launch Application
```bash
# Start the web application
streamlit run streamlit_integrated.py

# Application will be available at: http://localhost:8501
```

---

## ğŸ¯ Usage Examples

### 1. Location-Based Tree Recommendations
```
ğŸ“ Input Example:
- Latitude: 38.2527  
- Longitude: -85.7585
- Diameter: 25.4 cm
- Native Status: Yes
- City: Louisville
- State: Kentucky

ğŸŒ³ Expected Output:
1. American Elm (Confidence: 85%)
2. Red Oak (Confidence: 78%)
3. Sugar Maple (Confidence: 72%)
4. Tulip Tree (Confidence: 69%)
5. Black Walnut (Confidence: 65%)
```

### 2. Species Distribution Query
```
ğŸ” Input: "Red Oak"
ğŸ“Š Output: Geographic distribution map showing prevalence in:
- Chicago, IL (15,432 trees)
- Louisville, KY (8,921 trees)  
- Atlanta, GA (6,543 trees)
- [Additional cities...]
```

### 3. Image Classification
```
ğŸ“¸ Input: Upload tree image (JPG/PNG)
ğŸ¤– AI Analysis: 
- Primary Prediction: "Sugar Maple" (34.2%)
- Secondary: "Red Maple" (28.7%)
- Tertiary: "Norway Maple" (22.1%)
- Confidence Threshold: >25% for reliable prediction
```

---

## ğŸ“ˆ Performance Metrics & Limitations

<div align="center">
<img src="docs/performance_metrics.png" alt="Performance Metrics" width="800">
<p><em>Model Performance Comparison: Dataset Sizes and Response Times</em></p>
</div>

### Model Performance
| **Model** | **Accuracy** | **Dataset Size** | **Training Time** |
|-----------|--------------|------------------|-------------------|
| KNN Recommender | N/A (Distance-based) | 1.38M records | ~30 seconds |
| CNN Classifier | ~26% validation | 1,454 images | ~2 hours |

<div align="center">
<img src="docs/data_distribution.png" alt="Data Distribution" width="800">
<p><em>Dataset Analytics: Geographic Distribution, Species Frequency, and Tree Characteristics</em></p>
</div>

### Known Limitations
- **CNN Accuracy**: Limited by small training dataset (1,454 images for 30 classes)
- **Geographic Bias**: Dataset primarily covers U.S. cities
- **Image Quality**: Performance varies with lighting, angle, and image clarity
- **Species Coverage**: Limited to 30 common North American species

### Future Improvements
- [ ] Expand image dataset with data augmentation techniques
- [ ] Include international tree species and locations
- [ ] Implement ensemble methods for improved accuracy
- [ ] Add leaf shape and bark texture analysis
- [ ] Mobile application development

---

## ğŸš€ Deployment Options

### Local Development
```bash
streamlit run streamlit_integrated.py
```

### Docker Deployment
```dockerfile
FROM python:3.13-slim
COPY . /app
WORKDIR /app
RUN pip install -r requirements.txt
EXPOSE 8501
CMD ["streamlit", "run", "streamlit_integrated.py"]
```

### Cloud Platforms
- **Streamlit Cloud**: Direct GitHub integration
- **Heroku**: Web application hosting
- **AWS/GCP/Azure**: Scalable cloud deployment
- **Docker**: Containerized deployment

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

### Areas for Contribution
- ğŸ–¼ï¸ **Dataset Expansion**: Add more tree species images
- ğŸŒ **Geographic Coverage**: Include international tree data
- ğŸ§  **Model Improvements**: Enhance CNN architecture
- ğŸ¨ **UI/UX**: Improve web interface design
- ğŸ“± **Mobile Support**: Responsive design enhancements

### Development Workflow
1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Code Standards
- Follow PEP 8 Python style guidelines
- Add docstrings for new functions
- Include unit tests for new features
- Update documentation for API changes

---


---

<div align="center">

**â­ Star this repository if you found it helpful!**

Made with â¤ï¸ for urban forestry and environmental conservation

</div>
